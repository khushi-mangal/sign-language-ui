ğŸ“˜ Smart India Hackathon 2025 â€” Project Documentation
Team: Shunya
Project Title: Adaptive ISL Smart Glove â€” A Gamified Edge-AI System for Real-Time Sign Language Translation
1. Problem Statement

Hearing and speech-impaired individuals face major communication challenges in daily life due to the lack of real-time, adaptive, and user-friendly Indian Sign Language (ISL) systems.

Most existing ISL solutions have these limitations:

Require large pre-trained datasets

Lack adaptability for new signs

Provide minimal user interaction or feedback

Do not support continuous learning from users

To address these gaps, the Adaptive ISL Smart Glove introduces a gamified training experience and adaptive learning logic powered by BLE-based edge communication, making ISL translation efficient, interactive, and personalized.

---

2. Project Overview

The Adaptive ISL Smart Glove is a 3-phase gamified AI system designed for gesture learning, live translation, and user customization.
It combines adaptive logic with an engaging training workflow to make gesture learning both effective and enjoyable.

The system operates across three integrated phases:

ğŸ§© Training Phase â€” Learn and train gestures with gamified feedback.

ğŸ”Š Live Communication Phase â€” Perform gestures for real-time translation.

âœ‹ Customization Phase â€” Create and label new gestures for personal use.

Each phase uses Bluetooth Low Energy (BLE) communication for real-time data exchange between the glove and the mobile/web application.

---


3. Objectives

Build a BLE-based adaptive ISL glove for real-time sign translation and gamified learning.

Develop a multi-phase adaptive training system that evolves with each user.

Use adaptive permutation logic to reduce dataset dependency and exponentially expand vocabulary.

Allow custom gesture creation and labeling through guided tutorials.

Deliver continuous learning and feedback through gamified visual cues.

---


4. Core Innovations
4.1 Adaptive Permutation Logic

The glove generates new signs from a few base gestures using lightweight adaptive logic â€” similar to how humans combine words to form new meanings.

Rules:

Max gesture length = 3

No consecutive repetition (AA âŒ)

Alternating repetition allowed (ABA âœ…)

Each sequence = unique meaning

Formula:
Total = N + N Ã— (N - 1) + N Ã— (N - 1) Ã— (N - 1)

Example:

3 base gestures â†’ 21 adaptive words

10 base gestures â†’ 910 adaptive words

This drastically reduces training time while maintaining scalability and accuracy.

4.2 Gamified Training Framework
Feature	Description
Accuracy Feedback	Real-time accuracy bar with color-coded evaluation.
Progress Tracking	Incremental growth bars for gesture mastery.
Rewards & Levels	Unlocks next gesture after hitting target accuracy.
Feedback Loop	â€œExcellent / Retryâ€ cues motivate consistent practice.

The system â€œlearns while you playâ€ â€” turning learning into an interactive challenge.

---

5. System Workflow â€” 3 Phases


ğŸ§© Phase 1: Training (Gamified Learning)

User clicks â€œTrain A/B/Câ€ â†’ Glove sends BLE sensor data.

The adaptive dashboard simulates or reads live data.

If readings fall within adaptive thresholds â†’ Accuracy shown and gesture recorded.

Continuous feedback loop improves precision.


ğŸ”Š Phase 2: Communication (Live Mode)

Real-time sensor data â†’ BLE â†’ App â†’ Text/Speech output.

Recognized gesture â†’ Translated instantly into text or audio feedback.

Accuracy used for self-learning reinforcement.


âœ‹ Phase 3: Customization

User performs new gesture 5Ã— â†’ glove checks variance threshold.

If stable, system allows naming (e.g., â€œHelpâ€, â€œEmergencyâ€).

Added to dataset for future translation.

---


6. Implementation Details
Module	Description
Mobile UI (Figma + Web)	Gamified front-end simulation for training and live translation.
Adaptive Dashboard (Web Demo)	Real-time visualization, training logic, accuracy tracking.
Simulation Layer (/simulation/)	Generates mock BLE packets (10 sensors) for testing without hardware.
Glove Hardware (/hardware/)	ESP32-based circuit integrating 5 Flex + 5 Pressure sensors + IMU via IÂ²C.
Firmware (adaptive_glove_ble.ino)	Reads sensor data, normalizes, and transmits via BLE every 200 ms.

---

7. Hardware Integration

Controller: ESP32-WROOM-32
Sensors:

5 Ã— Flex Sensors (finger bends)

5 Ã— Pressure Sensors (finger tips)

1 Ã— IMU (orientation tracking)

Connection Summary:

Flex Sensors â†’ ADC Pins (34â€“33)

Pressure Sensors â†’ ADC Pins (25â€“29)

IMU (MPU6050) â†’ SDA (21), SCL (22)

RGB LED â†’ GPIO 2 (status indicator)

---

âš™ï¸ ESP32 Setup

To run /hardware/firmware.ino, install:

Libraries:

ESP32 BLE Arduino

Wire (built-in)

MPU6050 (by Electronic Cats / Jeff Rowberg)

Steps:

Add board URL â†’ https://dl.espressif.com/dl/package_esp32_index.json

Select Board: ESP32 Dev Module

Set Baud Rate: 115200

Upload the code ğŸš€

---


8. Simulation Layer (No Hardware Needed)

Located in /simulation/mock_ble_stream.js

Purpose:

Simulates 10-sensor BLE data (5 Flex + 5 Pressure + IMU)

Triggered only when user clicks Train A/B/C

Streams mock data every 100â€“150 ms for 1 second

Allows complete dashboard testing without physical glove

This enables smooth demonstration even without hardware connectivity.

---

9. Results
Parameter	Outcome
Base Gestures Trained	3
Adaptive Combinations	21
Accuracy Range	70â€“95% (adaptive simulated)
BLE Transfer Latency	< 50 ms
Real Hardware Compilation	âœ… Successful
Gamified UI	âœ… Integrated

---

10. Future Scope

Full hardware deployment with calibrated sensor array.

Flutter BLE app integration for mobile use.

On-device edge inference using TensorFlow Lite Micro.

Gesture dataset cloud sync for personalization.

Dual-mode communication (Gesture â†” Voice/Text).

---

11. Tech Stack
Layer	Tools & Technologies
Frontend	HTML, CSS, JavaScript
UI Design	Figma (Mobile App Prototype)
Logic Engine	Adaptive Permutation Algorithm
Communication	Bluetooth Low Energy (ESP32)
Gamification	Real-time Accuracy & Progress System
Hardware	ESP32 + 5 Flex + 5 Pressure + IMU

---

12. Conclusion

The Adaptive ISL Smart Glove merges hardware, AI, and gamification into one adaptive learning ecosystem.
Through BLE-based communication, real-time feedback, and adaptive logic, it enables expressive communication for everyone.

---

â€œTrain less, express more â€” where every gesture learns to speak.â€ ğŸ’¡

Team Shunya | Smart India Hackathon 2025