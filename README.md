# ğŸŒ Adaptive ISL Smart Glove  
### Gamified Edge-AI System for Real-Time Sign Language Translation  
#### Team: *Shunya* | Smart India Hackathon 2025  

---

## ğŸ§  Overview  
The *Adaptive ISL Smart Glove* bridges accessibility and AI through *gamified gesture learning* and *adaptive permutation logic*.  
It enables real-time translation of Indian Sign Language (ISL) while creating an *interactive, game-like learning experience* for users who cannot hear or speak.  

Our system learns new words from just a few base gestures â€” showing how AI can â€œplay to learn,â€ not just train on data.

---

## ğŸ¯ Problem & Solution  
Traditional sign language systems are dataset-heavy, non-adaptive, and lack engagement.  
Users need a more *interactive way to train gestures, and systems need to **adapt dynamically* rather than being re-trained.

Our glove combines:
- *Gamified learning* for motivation and real-time feedback ğŸ®  
- *Adaptive logic* that creates new words using trained gestures ğŸ§©  
- *Sensor fusion (Flex, IMU, Pressure)* for real-time validation âš™  

---

## ğŸ® Gamification at the Core  
| Feature | Description |
|:--|:--|
| ğŸ¯ *Accuracy Feedback* | Visual bars show how close the gesture matches the trained pattern. |
| ğŸ§© *Levels & Progress* | Users unlock new gestures after reaching certain accuracy. |
| ğŸŒŸ *Adaptive Scoring* | AI rewards consistent improvement and confidence over time. |
| ğŸ•¹ *Practice Mode* | Each gesture can be replayed, corrected, and trained again. |

> The more users â€œplayâ€ with gestures, the smarter the glove becomes â€” learning like a human brain.

---

## ğŸ§® Adaptive Gesture Logic  
Instead of training 100+ signs, we train a few and *generate new combinations* using permutation-based AI logic.

*Rule Set:*  
- Maximum gesture length = 3  
- No consecutive repetition (AA âŒ)  
- Alternating repetition allowed (ABA âœ…)  
- Each valid combination = unique meaning  

*Formula:*

Total = N + N Ã— (N - 1) + N Ã— (N - 1) Ã— (N - 1)

*Example:*  
- 3 trained gestures â†’ 21 unique words  
- 10 trained gestures â†’ 910 unique words  

This logic makes the system scalable â€” from a small training set to a rich sign vocabulary.

---

## âš™ Tech Stack  
*Frontend:* HTML, CSS, JavaScript  
*Design:* Figma (Web-based mobile UI simulation)  
*Core Logic:* Adaptive Permutation Engine (Custom JS)  
*Gamification Layer:* Real-time accuracy, progress tracking, rewards  
*Hardware (Future):* Flex, IMU, and Pressure sensors for validation

---

ğŸ“ Repository Structure

src/        â†’ Figma-based UI (Gamified Mobile Simulation)
web_demo/   â†’ Adaptive Gesture Dashboard (Working Logic Prototype)
docs/       â†’ SIH Project Documentation (Detailed Report)


---

ğŸ§© Future Development

Integration with actual sensor gloves (Flex, IMU, Pressure)

Edge-level learning via TensorFlow Lite Micro

Gamified progress dashboard with AI-generated feedback

BLE + ESP32-based hardware prototype

Mobile app (Flutter BLE) for real-time ISL translation



---


## â–¶ Run Instructions  

### ğŸ§© Adaptive Dashboard (Main Prototype)  
1. Clone the repository  
   ```bash
   git clone https://github.com/khushi-mangal/sign-language-ui

2. Open /web_demo/index.html in VS Code Live Server


3. Train gestures (A, B, Câ€¦) and watch the adaptive learning dashboard in action!



ğŸ¨ Figma-Based Web UI (Mobile Simulation)

1. Run locally for the UI prototype

cd sign-language-ui
npm install
npm run dev


2. Explore the gamified mobile interface built in Figma â†’ Web.

---

> â€œGamification is how humans learn â€” our glove makes AI learn the same way.â€ ğŸ®ğŸ§ 
Team Shunya




  