ğŸ§© Judges Run Instructions â€” Adaptive ISL Smart Glove (SIH 2025)

Team: Shunya
Project: Adaptive ISL Smart Glove â€” A Gamified Edge-AI System for Real-Time Sign Language Translation


---
### For main ML based Dashboard 

âš™ 1ï¸âƒ£ Clone the Repository

git clone https://github.com/khushi-mangal/sign-language-ui
cd sign-language-ui/web_demo/ml

(Ensures all dependencies and model files are in place.)

ğŸ§  2ï¸âƒ£ Train the ML Model (One-Time Setup)

python ml_train.py

This will:

Load base gesture data (A, B, C)
Auto-generate new combinations (AB, AC, ABC, etc.)
Train a RandomForest model
Save the trained model â†’ models/rf_model.joblib
Store dataset progress â†’ models/progress.json


> âœ… Only needs to be run once unless you wish to retrain.


ğŸŒ 3ï¸âƒ£ Start the ML WebSocket Server

python server.py

This launches the real-time ML backend responsible for:

Receiving BLE / simulated sensor data
Handling live training updates
Performing gesture predictions


Youâ€™ll see logs like:

ğŸ§  Loaded trained model: rf_model.joblib  
ğŸŒ Starting ML WebSocket server on ws://0.0.0.0:8765 â€¦
âš¡ Client connected


ğŸ’» 4ï¸âƒ£ Launch the Adaptive Dashboard

Open the following file in VS Code Live Server:

/web_demo/index.html

Once opened:

It auto-connects to the running ML WebSocket server
Dashboard loads gesture buttons (Train A / Train B / Train C)

âœ‹ 5ï¸âƒ£ Start Training Gestures

Click any gesture (A, B, or C) and observe:
Live sensor simulation
Progress bars fill dynamically (0 â†’ 500 scale)

---

ğŸ¨ 6ï¸ Figma-Based Mobile UI

For mobile simulation of the gamified interface(BASIC ONE):

cd sign-language-ui
npm install
npm run dev

Explore the Figma-inspired frontend, built with HTML + JS logic, simulating live training and AI feedback.

### ğŸ§¾ Quick Verification (Judge Checklist)
âœ… Step 1: Run python server.py â†’ Server starts successfully  
âœ… Step 2: Open index.html â†’ Dashboard connects automatically  
âœ… Step 3: Click Train A/B/C â†’ Bars fill (e.g., A: 25/500)  
âœ… Step 4: Observe console â†’ â€œâœ… Saved window for A (25/500)â€   

If all above appear, the system is fully functional.

### ğŸ§  Notes
- No physical hardware required; BLE data auto-simulated.  
- Progress is persistent (remains even after refresh).  
- Compatible with Python 3.9 â€“ 3.12 and latest WebSocket versions.  
- Entire system runs locally â€” no external dependencies.

### ğŸ¤ Team & Credits
Developed by Team Shunya  
Smart India Hackathon 2025 Final Prototype â€” Adaptive ISL Smart Glove